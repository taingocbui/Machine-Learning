{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_congress_data(training_ratio):\n",
    "    \"\"\"Load the congress data.\n",
    "\n",
    "    Note that missing values (denoted '?', where a voter abstained) are \n",
    "    instead treated as a third type of attribute. Therefore every feature\n",
    "    has 3 possible attributes.\n",
    "\n",
    "    Args:\n",
    "        training_ratio: the ratio of examples that go into the training set\n",
    "    Returns:\n",
    "        a tuple of numpy matrices, the first in the tuple is the training \n",
    "        data, second is test data. Each matrix row represents a data point \n",
    "        as a row vector: the first element of the row vector corresponds to \n",
    "        the label and the following elements correspond to attributes.\n",
    "    \"\"\"\n",
    "    random.seed(1) # get same data every time\n",
    "    label_conversions = {'republican' : 0, 'democrat' : 1, \n",
    "                         'n' : 0, 'y' : 1, '?' : 2} \n",
    "    f = open('data/house-votes-84.data', 'r')\n",
    "\n",
    "    training = None\n",
    "    test = None\n",
    "    lines = f.readlines()\n",
    "    train_index = int(len(lines)*training_ratio)\n",
    "    random.shuffle(lines)\n",
    "    for k, line in enumerate(lines):\n",
    "        data = line.split(',')\n",
    "        vector = [float(label_conversions[i.rstrip('\\n')]) for i in data]\n",
    "        vector = np.array(vector)\n",
    "        if k < train_index:\n",
    "            if training is None:\n",
    "                training = vector\n",
    "            else:\n",
    "                training = np.vstack((training, vector))\n",
    "        else:\n",
    "            if test is None:\n",
    "                test = vector\n",
    "            else:\n",
    "                test = np.vstack((test, vector))\n",
    "    return (training, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S is a numpy array\n",
    "# this function returns sigmoid function of each element of S\n",
    "def sigmoid(S):\n",
    "    return 1/(1+ np.exp(-S))\n",
    "\n",
    "# X is a 2 dimenstions numpy array with N datapoints and d features\n",
    "# w is a 1 dimension numpy array of shape d\n",
    "# this function returns sigmoid function of the dot product between X and w\n",
    "def prob(w, X):\n",
    "    return sigmoid(np.dot(X, w))\n",
    "\n",
    "#This function returns the value of the loss function given vector w, 2-d matrix X and vector label y\n",
    "def loss(w, X, y):\n",
    "    g = prob(w, X)\n",
    "    return -np.mean(y*np.log(g) + (1-y)*np.log(1-g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This function returns the logistic weigth vector with size d\n",
    "def logistic_regression(w_init, X, y, ep, threshold):\n",
    "    (N, d) = X.shape[0], X.shape[1]\n",
    "    weight = []\n",
    "    w = w_old = w_init\n",
    "    loss_hist = [loss(w_init,X,y)]\n",
    "    for i in range(0,N):\n",
    "        xi = X[i]\n",
    "        yi = y[i]\n",
    "        gi = sigmoid(np.dot(xi,w))\n",
    "        \n",
    "        w = w - ep*((gi - yi) * xi)\n",
    "        old_loss = loss(w_old,X,y)\n",
    "        new_loss = loss(w, X,y)\n",
    "        if np.abs(old_loss - new_loss) < threshold:\n",
    "            break\n",
    "        w_old = w\n",
    "    return w\n",
    "\n",
    "\n",
    "#This function returns a list of prediction for each data point of test set\n",
    "def predict(training, test):    \n",
    "    y_train = np.transpose(training)[0]\n",
    "    X_train = np.delete(training, 0, axis=1)\n",
    "    y_test = np.transpose(test)[0]\n",
    "    X_test = np.delete(test, 0, axis=1)\n",
    "    d = X_train.shape[1]\n",
    "    w_init = np.random.randn(X_train.shape[1])\n",
    "    ep = 0.1\n",
    "    threshold = 0.000001\n",
    "    weight = logistic_regression(w_init, X_train, y_train, ep, threshold)\n",
    "    prediction=[]\n",
    "    for i in range(0, y_test.shape[0]):\n",
    "        plabel = sigmoid(np.dot(weight, X_test[i]))\n",
    "        if plabel > 0.5:\n",
    "            prediction.append(1)\n",
    "        else:\n",
    "            prediction.append(0)\n",
    "    return prediction\n",
    "\n",
    "#This function returns the accuracy_score of the logistic regression\n",
    "def accuracy_score(test, prediction):\n",
    "    y_test = np.transpose(test)[0]\n",
    "    count = 0\n",
    "    for i in range(0, len(prediction)):\n",
    "        if y_test[i] == prediction[i]:\n",
    "            count+=1\n",
    "    return count/len(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is  0.9080459770114943\n"
     ]
    }
   ],
   "source": [
    "(training, test) = load_congress_data(0.6)\n",
    "acc = accuracy_score(test, predict(training, test))\n",
    "print(\"The accuracy is \",acc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
