{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tree decision score with entropy is  0.8\n",
      "The tree decision score with gini index is  0.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "def load_iris(training_ratio):\n",
    "    \"\"\"Load the iris data.\n",
    "\n",
    "    Args:\n",
    "        training_ratio: the ratio of examples that go into the training set\n",
    "    Returns:\n",
    "        a tuple of numpy matrices, the first in the tuple is the training \n",
    "        data, second is test data. Each matrix row represents a data point \n",
    "        as a row vector: the first element of the row vector corresponds to \n",
    "        the label and the following elements correspond to attributes.\n",
    "    \"\"\"\n",
    "    random.seed(1) # get same data every time\n",
    "    iris_labels = {'Iris-setosa': 0, 'Iris-versicolor' : 1, 'Iris-virginica' : 2}\n",
    "    f = open('data/iris.data', 'r')\n",
    "\n",
    "    training = None\n",
    "    test = None\n",
    "    lines = f.readlines()\n",
    "    train_index = int(len(lines)*training_ratio)\n",
    "    random.shuffle(lines)\n",
    "    for k, line in enumerate(lines):\n",
    "        data = line.split(',')\n",
    "        vector = [int(iris_labels[data[-1].rstrip('\\n')])]+ [float(i) for i in data[0:-1]]\n",
    "        vector = np.array(vector)\n",
    "        if k < train_index:\n",
    "            if training is None:\n",
    "                training = vector\n",
    "            else:\n",
    "                training = np.vstack((training, vector))\n",
    "        else:\n",
    "            if test is None:\n",
    "                test = vector\n",
    "            else:\n",
    "                test = np.vstack((test, vector))\n",
    "    return (training, test)\n",
    "\n",
    "class TreeNode(object):\n",
    "    def __init__(self, ids = None, children = [], depth = 0):\n",
    "        self.ids = ids           # index of data in this node\n",
    "        self.depth = depth       # distance to root node\n",
    "        self.split_attribute = None # which attribute is chosen, it non-leaf\n",
    "        self.children = children # list of its child nodes\n",
    "        self.order = None       # order of values of split_attribute in children\n",
    "        self.label = None       # label of node if it is a leaf\n",
    "    \n",
    "    #this function will set the split_attribute and the values of \n",
    "    #split_attribute in children corresponding to the node\n",
    "    def set_properties(self, split_attribute, order):\n",
    "        self.split_attribute = split_attribute\n",
    "        self.order = order\n",
    "    \n",
    "    #this function will set the label for the leaf node\n",
    "    def set_label(self, label):\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def entropy(freq, model):\n",
    "    #this function will calculate the entropy values for each values in a particular feature\n",
    "    #if model = \"gini\", it will returns value based on gini index formula\n",
    "    #if model = \"entropy\", it will returns value based on entropy formula\n",
    "    prob_0 = freq/float(freq.sum())\n",
    "    if model == \"entropy\":\n",
    "    #calulate using entropy\n",
    "        return -np.sum(prob_0*np.log(prob_0))\n",
    "    if model == \"gini\":\n",
    "    #calulate using gini index\n",
    "        return 2*np.prod(prob_0)        \n",
    "        \n",
    "class DecisionTree(object):\n",
    "    def __init__(self, model = \"entropy\"):\n",
    "        self.root = None \n",
    "        self.max_depth = 0\n",
    "        self.Ntrain = 0\n",
    "        self.model = model\n",
    "    def fit(self, data, target):\n",
    "        self.Ntrain = data.count()[1]\n",
    "        self.data = data #this is a matrix of N data points with each column is a feature\n",
    "        self.attributes = list(data.columns) #list of name of the features\n",
    "        self.target = target #this is a matrix of N data points, each is a label\n",
    "        self.labels = target.unique() #list of unique labels\n",
    "        self.max_depth = len(self.attributes) #the max_depth will be set to be the number of features\n",
    "        \n",
    "        ids = range(self.Ntrain)\n",
    "        self.root = TreeNode(ids = ids, depth = 0)\n",
    "        queue = [self.root]\n",
    "        while queue:\n",
    "            node = queue.pop()\n",
    "            if node.depth < self.max_depth:\n",
    "                #function _split will both store best_attribute after entropy calculation in the node\n",
    "                #and returns a list of children, with each children is a split accordingly\n",
    "                node.children = self._split(node)\n",
    "                if not node.children: #leaf node, then set label and store into the node\n",
    "                    self._set_label(node)\n",
    "                queue += node.children #add the children to the node to continue growing the tree\n",
    "            else:\n",
    "                self._set_label(node) #if the depth is at its max, then set label corresponding to the node\n",
    "        \n",
    "    def _entropy(self, ids):\n",
    "        # calculate entropy of a node with index ids\n",
    "        if len(ids) == 0: return 0\n",
    "        freq = np.array(self.target[ids].value_counts())\n",
    "        return entropy(freq, self.model)\n",
    "    \n",
    "    def _set_label(self, node):\n",
    "        # find label for a node if it is a leaf\n",
    "        # simply chose by major voting \n",
    "        target_ids = [i for i in node.ids]  # target is a series variable\n",
    "        node.set_label(self.target[target_ids].mode()[0]) # most frequent label\n",
    "        \n",
    "    def _split(self, node):\n",
    "        ids = node.ids \n",
    "        best_splits = []\n",
    "        best_attribute = None\n",
    "        order = None\n",
    "        sub_data = self.data.iloc[ids, :] #split data according to the list of ids stored in the node\n",
    "        \n",
    "        minG = 1\n",
    "        for i, att in enumerate(self.attributes):\n",
    "            values = self.data.iloc[ids, i].unique().tolist() \n",
    "            if len(values) == 1: continue # homogenous for this attribute feature, then continue\n",
    "            splits = []\n",
    "            for val in values: \n",
    "                #for each value in the attribute, we will obtain the index of all data that have the same value \n",
    "                #and add them into a list\n",
    "                sub_ids = sub_data.index[sub_data[att] == val].tolist() \n",
    "                splits.append([sub_id for sub_id in sub_ids])\n",
    "            if min(map(len, splits)) == 0: continue #if the split data is empty, then continue\n",
    "            Entropy = 0\n",
    "            for split in splits:\n",
    "                Entropy += len(split)*self._entropy(split)/len(ids)\n",
    "            #we will choose the attribute with the minimum entropy value\n",
    "            if Entropy < minG:\n",
    "                minG = Entropy\n",
    "                best_attribute = att\n",
    "                best_splits = splits\n",
    "                order = values\n",
    "        #set the best_attribute for the node\n",
    "        node.set_properties(best_attribute, order)\n",
    "        #create a list of children nodes according to split ids obtained from best_splits\n",
    "        child_nodes = [TreeNode(ids = split,\n",
    "                     depth = node.depth + 1) for split in best_splits]\n",
    "        return child_nodes\n",
    "    \n",
    "    def predict(self, new_data):\n",
    "        \n",
    "        #param new_data: a new dataframe, each row is a datapoint\n",
    "        #return: predicted labels for each row\n",
    "        npoints = new_data.count()[1]\n",
    "        labels = [None]*npoints\n",
    "        for n in range(npoints):\n",
    "            x = new_data.iloc[n, :] # one point \n",
    "            # start from root and recursively travel if not meet a leaf \n",
    "            node = self.root\n",
    "            while node.children: \n",
    "                #if the value in test set is not covered in training set, default to pick the first children node\n",
    "                if x[node.split_attribute] not in node.order:\n",
    "                    node = node.children[0]\n",
    "                else:\n",
    "                    node = node.children[node.order.index(x[node.split_attribute])]                \n",
    "            labels[n] = node.label\n",
    "            \n",
    "        return labels\n",
    "\n",
    "def get_score(predict, target):\n",
    "    #this function returns the accuracy of our decision tree\n",
    "    count = 0\n",
    "    for i in range(target.shape[0]):\n",
    "        if target[i] == predict[i]:\n",
    "            count+=1\n",
    "    return count/target.shape[0]\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    training, test = load_iris(0.6)\n",
    "    df1 = pd.DataFrame(training)\n",
    "    df2 = pd.DataFrame(test)\n",
    "    X_train = df1.iloc[:, 1:]\n",
    "    y_train = df1.iloc[:, 0]\n",
    "    X_test = df2.iloc[:, 1:]\n",
    "    y_test = df2.iloc[:, 0]\n",
    "    tree1 = DecisionTree(model = \"entropy\")\n",
    "    tree1.fit(X_train, y_train)\n",
    "    prediction1 = tree1.predict(X_test)\n",
    "    tree2  = DecisionTree(model= \"gini\")\n",
    "    tree2.fit(X_train, y_train)\n",
    "    prediction2 = tree2.predict(X_test)\n",
    "    return (get_score(prediction1, y_test),get_score(prediction2, y_test))\n",
    "\n",
    "\n",
    "entropy_score, gini_score = main()\n",
    "print(\"The tree decision score with entropy is \",entropy_score)\n",
    "print(\"The tree decision score with gini index is \",gini_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
